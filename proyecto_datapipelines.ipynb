{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Data Pipelines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import boto3\n",
    "import psycopg2\n",
    "import configparser\n",
    "import random\n",
    "from faker import Faker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Se carga el archivo de configuracion y se establece el nombre de la instancia de RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdsIdentifier = 'proyecto-db-1' #nombre de la instancia en AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['escec.cfg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('escec.cfg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creamos instancia de RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_conn = boto3.client('rds', aws_access_key_id=config.get('IAM', 'ACCESS_KEY'),\n",
    "                    aws_secret_access_key=config.get('IAM', 'SECRET_ACCESS_KEY'),\n",
    "                    region_name='us-east-1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verificamos Instancias de RDS Disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBInstanceIds ['proyecto-db-1', 'proyecto-db-2']\n"
     ]
    }
   ],
   "source": [
    "rdsInstanceIds = []\n",
    "\n",
    "response = aws_conn.describe_db_instances()\n",
    "for resp in response['DBInstances']:\n",
    "    rdsInstanceIds.append(resp['DBInstanceIdentifier'])\n",
    "    db_instance_status = resp['DBInstanceStatus']\n",
    "\n",
    "print(f\"DBInstanceIds {rdsInstanceIds}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creacion de Servicio RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Instancia de Base de Datos ya Existe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = aws_conn.create_db_instance(\n",
    "            AllocatedStorage=10,\n",
    "            DBName=config.get('RDS', 'DB_NAME'),\n",
    "            DBInstanceIdentifier=rdsIdentifier,\n",
    "            DBInstanceClass=\"db.t3.micro\",\n",
    "            Engine=\"postgres\",\n",
    "            MasterUsername=config.get('RDS', 'DB_USER'),\n",
    "            MasterUserPassword=config.get('RDS', 'DB_PASSWORD'),\n",
    "            Port=int(config.get('RDS', 'DB_PORT')),\n",
    "            VpcSecurityGroupIds=[config.get('VPC', 'SECURITY_GROUP')],\n",
    "            PubliclyAccessible=True\n",
    "        )\n",
    "    print(response)\n",
    "except aws_conn.exceptions.DBInstanceAlreadyExistsFault as ex:\n",
    "    print(\"La Instancia de Base de Datos ya Existe.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Obtenemos URL del Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proyecto-db-1.ckhzkzfbezed.us-east-1.rds.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "     instances = aws_conn.describe_db_instances(DBInstanceIdentifier=rdsIdentifier)\n",
    "     RDS_HOST = instances.get('DBInstances')[0].get('Endpoint').get('Address')\n",
    "     print(RDS_HOST)\n",
    "except Exception as ex:\n",
    "     print(\"La instancia de base de datos no existe o aun no se ha terminado de crear.\")\n",
    "     print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conexion a base de datos con Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de Datos Creada Exitosamente\n"
     ]
    }
   ],
   "source": [
    "import DDL_UNO\n",
    "\n",
    "try:\n",
    "    db_conn = psycopg2.connect(\n",
    "        database=config.get('RDS', 'DB_NAME'), \n",
    "        user=config.get('RDS', 'DB_USER'),\n",
    "        password=config.get('RDS', 'DB_PASSWORD'), \n",
    "        host=RDS_HOST,\n",
    "        port=config.get('RDS', 'DB_PORT')\n",
    "    )\n",
    "\n",
    "    cursor = db_conn.cursor()\n",
    "    cursor.execute(DDL_UNO.DDL_T)\n",
    "    db_conn.commit()\n",
    "    print(\"Base de Datos Creada Exitosamente\")\n",
    "except Exception as ex:\n",
    "    print(\"ERROR: Error al crear la base de datos.\")\n",
    "    print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Definicion de funcion de \"InsertDataToSQL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertDataToSQL(data_dict, table_name):\n",
    "     postgres_driver = f\"\"\"postgresql://{config.get('RDS', 'DB_USER')}:{config.get('RDS', 'DB_PASSWORD')}@{RDS_HOST}:{config.get('RDS', 'DB_PORT')}/{config.get('RDS', 'DB_NAME')}\"\"\"    \n",
    "     df_data = pd.DataFrame.from_records(data_dict)\n",
    "     try:\n",
    "          response = df_data.to_sql(table_name, postgres_driver, index=False, if_exists='append')\n",
    "          print(f'Se han insertado {response} nuevos registros.' )\n",
    "     except Exception as ex:\n",
    "          print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Seccion Transaccional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Insercion de data a Tabla \"Branch\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1.1 Leemos un archivo de S3 que contiene la data de la tabla branch y luego la insertamos a la tabla branch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una instancia de la clase resource de boto3 y se accede al servicio de s3 con las credenciales de usuario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    service_name = 's3',\n",
    "    region_name = 'us-east-1',\n",
    "    aws_access_key_id = config.get('IAM', 'ACCESS_KEY'),\n",
    "    aws_secret_access_key = config.get('IAM', 'SECRET_ACCESS_KEY')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se obtienen los buckets existentes en la cuenta AWS y se asigna a la variable S3_BUCKET_NAME el nombre del bucket necesario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proyecto-data-pipeline-galileo1\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3.buckets.all():\n",
    "    S3_BUCKET_NAME = bucket.name\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET_NAME = 'proyecto-data-pipeline-galileo1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se obtiene una lista de lo almacenado en el bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['branch.csv', 'customer_type.xlsx']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remoteFileList = []\n",
    "for objt in s3.Bucket(S3_BUCKET_NAME).objects.all():\n",
    "    remoteFileList.append(objt.key)\n",
    "\n",
    "remoteFileList"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se leen los archivos 'branch.csv' y 'customer_type.xlsx' y se asignan a un dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id branch\n",
      "0          1      A\n",
      "1          2      B\n",
      "2          3      C\n",
      "   customertype_id customer_type\n",
      "0                1        Member\n",
      "1                2        Normal\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "df_branch = pd.DataFrame()\n",
    "df_customer_type = pd.DataFrame()\n",
    "\n",
    "for remoteFile in remoteFileList:\n",
    "    try:\n",
    "        file = s3.Bucket(S3_BUCKET_NAME).Object(remoteFile).get()\n",
    "        if 'branch.csv' in remoteFile:\n",
    "            df_branch = pd.read_csv(file['Body'])\n",
    "        elif 'customer_type.xlsx' in remoteFile:\n",
    "            data = file['Body'].read()\n",
    "            df_customer_type = pd.read_excel(io.BytesIO(data), engine='openpyxl')\n",
    "    except Exception as ex:\n",
    "        print(\"No es un archivo.\")\n",
    "        print(ex)\n",
    "\n",
    "print(df_branch)\n",
    "print(df_customer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_branch = df_branch.to_dict('records')\n",
    "data_dict_customer_type = df_customer_type.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 3 nuevos registros.\n",
      "Se han insertado 2 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "insertDataToSQL(data_dict_branch, 'branch')\n",
    "insertDataToSQL(data_dict_customer_type, 'customer_type')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Insercion de data a Tabla \"City\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 3 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "data_city = [\n",
    "     {'city_id': 1, 'city_name': 'Mandalay'}, \n",
    "     {'city_id': 2, 'city_name': 'Yangon'},\n",
    "     {'city_id': 3, 'city_name': 'Napypyitaw'}\n",
    "]\n",
    "\n",
    "insertDataToSQL(data_city, 'city')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Insercion de data a Tabla \"Location\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como regla de negocio se tiene que cada ciudad puede tener una unica tienda de distinto branch, en este caso existen 3 branches (A, B,C) y 3 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 3 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "data_tiendas_ciudad = []\n",
    "\n",
    "for ciudad in range(len(data_city)):\n",
    "    for tienda in range(len(df_branch)):\n",
    "        \n",
    "       ciudad_tienda = {\n",
    "        'location_id': ciudad+1,\n",
    "        'city_loc_id': data_city[ciudad]['city_id'],\n",
    "        'branch_loc_id': df_branch.loc[tienda, 'branch_id']\n",
    "    } \n",
    "    \n",
    "    data_tiendas_ciudad.append(ciudad_tienda)\n",
    "\n",
    "insertDataToSQL(data_tiendas_ciudad, 'location')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Insercion de data a Tabla \"Product Line\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 6 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "data_productline = [\n",
    "     {'product_line_id': 1, 'product_line_name': 'Electronic accessories'}, \n",
    "     {'product_line_id': 2, 'product_line_name': 'Fashion accessories'},\n",
    "     {'product_line_id': 3, 'product_line_name': 'Health and beauty'},\n",
    "     {'product_line_id': 4, 'product_line_name': 'Food and beverages'},\n",
    "     {'product_line_id': 5, 'product_line_name': 'Home and lifestyle'},\n",
    "     {'product_line_id': 6, 'product_line_name': 'Sports and travel'}\n",
    "]\n",
    "\n",
    "insertDataToSQL(data_productline, 'product_line')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Insercion de data a Tabla \"Payment\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 3 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "data_payment = [\n",
    "     {'payment_id': 1, 'payment_type': 'Ewallet'},\n",
    "     {'payment_id': 2, 'payment_type': 'Cash'},\n",
    "     {'payment_id': 3, 'payment_type': 'Credit card'} \n",
    "]\n",
    "\n",
    "insertDataToSQL(data_payment, 'payment')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Insercion de data a Tabla \"Customer Gender\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: La insercion de data a la tabla Customer Type se realizo al obtener los archivos almacenados en S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 2 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "data_gender = [\n",
    "     {'customergender_id': 1, 'customer_gender': 'Female'},\n",
    "     {'customergender_id': 2, 'customer_gender': 'Male'}\n",
    "]\n",
    "\n",
    "insertDataToSQL(data_gender, 'customer_gender')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6 Insercion data a Tabla \"Customers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 965 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "cantidad_clientes = np.random.randint(0,1500)\n",
    "data_clientes = []\n",
    "nombre_fake = Faker()\n",
    "\n",
    "for x in range(cantidad_clientes):\n",
    "    \n",
    "    gender = random.sample(data_gender, 1)[0]['customergender_id'] # se genera primero el genero para saber si es hombre o mujer y con ello determinar el nombre que generar con Faker\n",
    "    \n",
    "    if gender == 1:\n",
    "        name = nombre_fake.name_female()\n",
    "    elif gender == 2:\n",
    "        name = nombre_fake.name_male()\n",
    "    else:\n",
    "        name = \"Indefinido\"\n",
    "\n",
    "    cliente = {\n",
    "        'customers_id': x+1,\n",
    "        'customer_name': name,\n",
    "        'type_customer_id': random.sample(data_dict_customer_type, 1)[0]['customertype_id'],\n",
    "        'gender_customer_id': gender,\n",
    "    } \n",
    "\n",
    "    data_clientes.append(cliente)\n",
    "\n",
    "insertDataToSQL(data_clientes, 'customers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.7 Insertamos data a Tabla \"Sale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 106 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "data_ventas = []\n",
    "cantidad_ventas = np.random.randint(500,2000)\n",
    "fecha_fake = Faker() #se volvio a instanciar Faker para comprension y distincion entre \"Fakers\"\n",
    "\n",
    "for ventas in range(cantidad_ventas):\n",
    "    \n",
    "    unit_price = np.round(np.random.uniform(0,1000),2)\n",
    "    tax_5 = unit_price*0.05\n",
    "    quantity = np.random.randint(0,20)\n",
    "    sale_total = (unit_price + tax_5)*quantity\n",
    "    sale_gross_income = sale_total * 0.10\n",
    "    \n",
    "    venta = {\n",
    "            'sale_id': ventas+1,\n",
    "            'sale_location_id': random.sample(data_tiendas_ciudad, 1)[0]['location_id'],\n",
    "            'sale_payment_type_id': random.sample(data_payment, 1)[0]['payment_id'],\n",
    "            'sale_product_line_id': random.sample(data_productline, 1)[0]['product_line_id'],\n",
    "            'sale_costumer_id': random.sample(data_clientes, 1)[0]['customers_id'],\n",
    "            'sale_date': fecha_fake.date_time_this_year(),\n",
    "            'sale_quantity': quantity,\n",
    "            'sale_unitprice': np.round(np.random.uniform(0,10000),2),\n",
    "            'sale_taxes': tax_5,\n",
    "            'sale_total': sale_total,\n",
    "            'sale_gross_income': sale_gross_income\n",
    "        }\n",
    "    data_ventas.append(venta)\n",
    "    \n",
    "insertDataToSQL(data_ventas,'sales')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
